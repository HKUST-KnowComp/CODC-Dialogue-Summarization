{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import wordnet as wn\n",
    "import os\n",
    "from utils import prepare_dataset, rf_clf, write_to_file, eval_ensemble\n",
    "\n",
    "min_depth = 4\n",
    "min_dist = 0\n",
    "filter_name = \"EMNLP_filter\"\n",
    "graph_filter_weight = False\n",
    "max_connect_dist = 4\n",
    "if graph_filter_weight:\n",
    "    graph_filter_name = \"weightfilter\"\n",
    "else:\n",
    "    graph_filter_name = \"nofilter\"\n",
    "\n",
    "proc_type = \"train\"    \n",
    "dial_path = \"concepts_file/dial_mindepth{}_{}_{}.npy\"    \n",
    "# concepts and CODCs\n",
    "dial_concepts = np.load(\n",
    "    dial_path.format(min_depth, filter_name, proc_type),\n",
    "    allow_pickle=True)\n",
    "desc_path = \"concepts_file/desc_mindepth{}_{}_{}_{}.npy\"\n",
    "desc_concepts_list = [np.load(desc_path.format(min_depth, filter_name, proc_type, i),\\\n",
    "                              allow_pickle=True)\\\n",
    "                     for i in range(5)]\n",
    "codc_path = \"concepts_file/codc_mindepth{}_{}_mindis{}_{}.npy\"\n",
    "codc_allcaps = np.load(\n",
    "    codc_path.format(min_depth, filter_name, 0, proc_type),\n",
    "    allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Random select from all codcs from 5 caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(229)\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from utils import get_f1\n",
    "codc_vocab = Counter(chain(*[[codc for codc, _ in codcs] for codcs in codc_allcaps]))\n",
    "codc_vocab_list = list(codc_vocab.keys())\n",
    "codc_allcaps_name = [list(set([codc for codc, _ in codcs])) for codcs in codc_allcaps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive proportion: 0.15 topk 5\n",
      "num pos: 0.14974125439867522\n",
      "number of zeros hits 42565\n",
      "(0.1497210722417719, 0.16800070498271907, 0.1483812305423733)\n"
     ]
    }
   ],
   "source": [
    "# retrieve top 1~10 knowledge\n",
    "# pos proportion ranges from \n",
    "\n",
    "for pos_prop in [0.15]:\n",
    "  for topk in [5]:\n",
    "    # start traversing\n",
    "    knowledge = []\n",
    "    for codcs_name in codc_allcaps_name:  \n",
    "      np.random.shuffle(codcs_name)\n",
    "      codc_idx = 0\n",
    "      know = []\n",
    "      \n",
    "      for is_pos in np.random.uniform(low=0.0, high=1.0, size=topk) < pos_prop:\n",
    "        if codc_idx < len(codcs_name) and is_pos:\n",
    "          know.append(codcs_name[codc_idx])\n",
    "          codc_idx += 1\n",
    "        else:\n",
    "          know.append(codc_vocab_list[np.random.randint(0, len(codc_vocab_list))])\n",
    "      knowledge.append(know)\n",
    "    print(\"positive proportion:\", pos_prop, \"topk\", topk)\n",
    "    print(\"num pos:\", sum([sum([k in codcs_name for k in know]) \\\n",
    "                       for codcs_name, know in zip(codc_allcaps_name, knowledge)]) \\\n",
    "                      / (len(codc_allcaps_name)* topk) )\n",
    "    print(get_f1(knowledge, codc_allcaps_name))\n",
    "    write_to_file(knowledge, \n",
    "      \"knowledge/train-knowledge/random-sample/top{}_prop{}_train.txt\".format(topk, pos_prop))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. For each cap, select several knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path = '/home/tfangaa/projects/Deprecate/see2017seq2seq/wn_data/wngraph/wngraph.pickle'\n",
    "G = nx.read_gpickle(graph_path).to_undirected()\n",
    "def get_graph_shortest_path(G, desc, dial):\n",
    "    try:\n",
    "        return len(nx.shortest_path(G, desc, dial))\n",
    "    except:\n",
    "        return 1e3\n",
    "shortest_path = lambda desc, dial: get_graph_shortest_path(G, desc, dial) - 2\n",
    "# 1. shouldn't be too close\n",
    "# 2. cy shouldn't be one of the hypernyms of cxs\n",
    "is_codc = lambda desc_synset, dial_synsets:\\\n",
    "  all(\n",
    "     shortest_path(desc_synset.name(), dial_synset.name())\\\n",
    "        >= min_distance for dial_synset in dial_synsets) and \\\n",
    "  all(desc_synset not in dial_synset.hypernyms() for dial_synset in dial_synsets)\n",
    "\n",
    "get_CODC = lambda dial_concepts, desc_concepts:\\\n",
    "  [desc_concept for desc_concept in desc_concepts \\\n",
    "     if is_codc(wn.synset(desc_concept[1]), [wn.synset(dial_concept[1]) for dial_concept in dial_concepts]) and \\\n",
    "      desc_concept[0] not in [dial_concept[0] for dial_concept in dial_concepts]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12815it [01:47, 121.26it/s]"
     ]
    }
   ],
   "source": [
    "# 1. get codcs individually\n",
    "\n",
    "\n",
    "codc_by_desc = []\n",
    "for i in range(5):\n",
    "    codcs = []\n",
    "    for dial_concept, desc_concept in tqdm(zip(dial_concepts, desc_concepts_list[i])):\n",
    "        codcs.append(get_CODC(dial_concept, desc_concept))\n",
    "    codc_by_desc.append(codcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96620it [15:42, 102.56it/s]\n",
      "96620it [15:41, 102.60it/s]\n",
      "96620it [15:47, 101.92it/s]\n",
      "96620it [16:47, 95.89it/s] \n",
      "96620it [16:47, 95.87it/s] \n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "def get_codc(dial_concepts, desc_concepts):\n",
    "  codcs = []\n",
    "  for dial_concept, desc_concept in tqdm(zip(dial_concepts, desc_concepts)):\n",
    "      codcs.append(get_CODC(dial_concept, desc_concept))\n",
    "  return codcs\n",
    "\n",
    "min_distance = 0\n",
    "workers = Pool(5)\n",
    "all_results = []\n",
    "for i in range(5):\n",
    "    tmp_result = workers.apply_async(\n",
    "      get_codc, \n",
    "      args=(\n",
    "            dial_concepts, \n",
    "            desc_concepts_list[i])\n",
    "        )\n",
    "    all_results.append(tmp_result)\n",
    "\n",
    "workers.close()\n",
    "workers.join()\n",
    "\n",
    "codc_by_desc = [tmp_result.get() for tmp_result in all_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483100 /home/tfangaa/projects/OpenNMT-py-summ/haojie/data/dialogs/dialog.train.5ref.txt\n",
      "483100 /home/tfangaa/projects/OpenNMT-py-summ/haojie/data/ground/desc.train.5ref.txt\n"
     ]
    }
   ],
   "source": [
    "!wc -l /home/tfangaa/projects/OpenNMT-py-summ/haojie/data/dialogs/dialog.train.5ref.txt\n",
    "!wc -l /home/tfangaa/projects/OpenNMT-py-summ/haojie/data/ground/desc.train.5ref.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482876 483100\n",
      "483100\n"
     ]
    }
   ],
   "source": [
    "# map from this to the dialog.train.5ref.txt\n",
    "\n",
    "dial_single_path = \"/home/tfangaa/projects/OpenNMT-py-summ/haojie/data/dialogs/dialog.train.5ref.txt.single\"\n",
    "desc_path = \"/home/tfangaa/projects/OpenNMT-py-summ/haojie/data/ground/desc.{}.5ref.txt.{}\" \n",
    "desc_5ref_path = \"/home/tfangaa/projects/OpenNMT-py-summ/haojie/data/ground/desc.train.5ref.txt\"\n",
    "dial_5ref_path = \"/home/tfangaa/projects/OpenNMT-py-summ/haojie/data/dialogs/dialog.train.5ref.txt\"\n",
    "\n",
    "dialogue_lines = open(dial_5ref_path).readlines()\n",
    "dial_single = open(dial_single_path).readlines()\n",
    "descs_seps = [open(desc_path.format(\"train\", i)).readlines() for i in range(5)]\n",
    "descs_5ref = open(desc_5ref_path).readlines()\n",
    "\n",
    "dial_desc_id_dict = dict()\n",
    "for i, (dial_line, desc_line) in enumerate(zip(dialogue_lines, descs_5ref)):\n",
    "  if (dial_line, desc_line) in dial_desc_id_dict:\n",
    "    if isinstance(dial_desc_id_dict[(dial_line, desc_line)], list):\n",
    "      dial_desc_id_dict[(dial_line, desc_line)].append(i)\n",
    "    else:\n",
    "      dial_desc_id_dict[(dial_line, desc_line)] = [dial_desc_id_dict[(dial_line, desc_line)], i]\n",
    "  else:\n",
    "    dial_desc_id_dict[(dial_line, desc_line)] = i\n",
    "\n",
    "print(len(dial_desc_id_dict), len(dialogue_lines))\n",
    "print( sum([len(val) if isinstance(val, list) else 1 for key, val in dial_desc_id_dict.items()]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483100\n"
     ]
    }
   ],
   "source": [
    "dial_desc_id_dict_copy = dial_desc_id_dict.copy()\n",
    "indexes = []\n",
    "for i in range(5):\n",
    "  index = []\n",
    "  for dial_line, desc_line in zip(dial_single, descs_seps[i]):\n",
    "    if isinstance(dial_desc_id_dict_copy[(dial_line, desc_line)], list):\n",
    "      idx = dial_desc_id_dict_copy[(dial_line, desc_line)][0]\n",
    "      index.append(idx)\n",
    "      dial_desc_id_dict_copy[(dial_line, desc_line)].remove(idx)\n",
    "    else:\n",
    "      index.append(dial_desc_id_dict_copy[(dial_line, desc_line)])\n",
    "  indexes.append(index)\n",
    "print(sum([len(set(item)) for item in indexes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_ascending = lambda l: all([l[i+1] > l[i]for i in range(len(l)-1)])\n",
    "all(is_ascending(indexes[i]) for i in range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_indexes = [idx for i, idx in enumerate(list(chain(*indexes)))]\n",
    "\n",
    "\n",
    "all(a == b for a, b in zip(list(chain(*descs_seps)), descs_5ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_codcs_5ref = list(chain(*codc_by_desc))\n",
    "all_codcs_5ref_names = [[codc for codc, _ in codcs] for codcs in all_codcs_5ref]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive proportion: 0.2 topk 3\n",
      "proportion of pos: 0.15352239011936797\n",
      "number of zeros hits 285377\n",
      "(0.15350893534809906, 0.29780502718491747, 0.193357866270669)\n",
      "positive proportion: 0.2 topk 5\n",
      "proportion of pos: 0.14016518319188573\n",
      "number of zeros hits 211075\n",
      "(0.14014196508659352, 0.43757336319813034, 0.204118928141822)\n",
      "positive proportion: 0.2 topk 6\n",
      "proportion of pos: 0.13380908024563581\n",
      "number of zeros hits 184394\n",
      "(0.13378603463741115, 0.4937968466881217, 0.20304827252440208)\n",
      "positive proportion: 0.2 topk 10\n",
      "proportion of pos: 0.11103829434899606\n",
      "number of zeros hits 121859\n",
      "(0.11100063823914996, 0.652663659215046, 0.18460491300637888)\n",
      "positive proportion: 0.4 topk 3\n",
      "proportion of pos: 0.27958186710825916\n",
      "number of zeros hits 165364\n",
      "(0.27957082729593596, 0.5198546124233873, 0.34686448230579886)\n",
      "positive proportion: 0.4 topk 5\n",
      "proportion of pos: 0.22983937073069757\n",
      "number of zeros hits 110025\n",
      "(0.22980780376733598, 0.6758936485327501, 0.3293991755360591)\n",
      "positive proportion: 0.4 topk 6\n",
      "proportion of pos: 0.20898571724280687\n",
      "number of zeros hits 97236\n",
      "(0.2089462499137515, 0.723518597332197, 0.31231208120285425)\n",
      "positive proportion: 0.4 topk 10\n",
      "proportion of pos: 0.14654274477333884\n",
      "number of zeros hits 80804\n",
      "(0.14648900043699262, 0.8107215817773155, 0.24102419282164492)\n"
     ]
    }
   ],
   "source": [
    "# retrieve top 1~10 knowledge\n",
    "# pos proportion ranges from \n",
    "\n",
    "for pos_prop in [0.2, 0.4]:\n",
    "  for topk in [3, 5, 6, 10]:\n",
    "    # start traversing\n",
    "    knowledge = []\n",
    "    for codcs_name in all_codcs_5ref_names:  \n",
    "      np.random.shuffle(codcs_name)\n",
    "      codc_idx = 0\n",
    "      know = []\n",
    "      \n",
    "      for is_pos in np.random.uniform(low=0.0, high=1.0, size=topk) < pos_prop:\n",
    "        if codc_idx < len(codcs_name) and is_pos:\n",
    "          know.append(codcs_name[codc_idx])\n",
    "          codc_idx += 1\n",
    "        else:\n",
    "          know.append(codc_vocab_list[np.random.randint(0, len(codc_vocab_list))])\n",
    "      knowledge.append(know)\n",
    "    print(\"positive proportion:\", pos_prop, \"topk\", topk)\n",
    "    print(\"proportion of pos:\", sum([sum([k in codcs_name for k in know]) \\\n",
    "                       for codcs_name, know in zip(all_codcs_5ref_names, knowledge)]) \\\n",
    "                      / (len(all_codcs_5ref_names)* topk) )\n",
    "    print(get_f1(knowledge, all_codcs_5ref_names))\n",
    "    write_to_file(knowledge, \n",
    "      \"knowledge/train-knowledge/random-fivecap/fivecap_top{}_prop{}_train.txt\".format(topk, pos_prop))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
