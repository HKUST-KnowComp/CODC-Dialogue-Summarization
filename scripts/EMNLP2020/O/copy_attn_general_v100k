python train.py -save_model models/baseline_O/copy_attn/v100k_general_copy_attn -data data/200enc_15dec_20kvocab -copy_attn -global_attention general -word_vec_size 128 -rnn_size 256 -layers 1 -encoder_type brnn -train_steps 400000 -max_grad_norm 2 -dropout 0. -batch_size 16 -valid_batch_size 16 -optim adagrad -learning_rate 0.15 -adagrad_accumulator_init 0.1 -reuse_copy_attn -copy_loss_by_seqlength -bridge -seed 229 -world_size 1 -gpu_ranks 0 -valid_steps 100000

python translate.py -gpu 1 \
   -batch_size 20 \
   -beam_size 4 \
   -model ../OpenNMT-py/models/baseline_O/copy_attn/v10k_general/v10k_general_copy_attn_step_100000.pt \
   -src dataset/Dial2Desc/dialog.test.txt \
   -output justatest \
   -min_length 5 \
   -max_length 15 \
   -verbose